{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README\n",
    "A notebook to compute evaluation scores for raw data as well as bacth corrected using besline methods: regressing batch effect out, ComBat and mnnCorrect. The workflow is run for both, the simulated and real-world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os \n",
    "import glob\n",
    "import sys\n",
    "from FlowCytometryTools import FCMeasurement\n",
    "from collections import Counter\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import xlrd\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "import scipy as sp\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from visualisation_and_evaluation.helpers_eval import cal_UMAP, entropy, cal_entropy, evaluate_scores, separate_metadata\n",
    "from baselines.baselines_helpers import scale, convert_to_ann, sample_cells, batch_correct, prep_anndata_for_eval, eval_batch_sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_raw(adata_full, samples_selected, save_path, suffix='full'):\n",
    "    # raw scores\n",
    "    adata_full_dict = dict()\n",
    "    for sample in samples_selected:\n",
    "        adata_full_dict[sample] = adata_full[adata_full.obs['sample']==sample].copy()\n",
    "    eval_full_raw = eval_batch_sample(adata_full_dict)\n",
    "    eval_full_raw['method'] = 'raw'\n",
    "    eval_full_raw.to_csv(save_path+'scores_raw_'+suffix+'.csv')\n",
    "    return(eval_full_raw)\n",
    "\n",
    "def wrapper_reg(adata_full, samples_selected, save_path, suffix='full'):\n",
    "    # regress out batch effect\n",
    "    adata_full_batch_reg = batch_correct(adata_full, method='reg')\n",
    "    eval_full_batch_reg = eval_batch_sample(adata_full_batch_reg)\n",
    "    eval_full_batch_reg['method'] = 'reg'\n",
    "    eval_full_batch_reg.to_csv(save_path+'scores_reg_'+suffix+'.csv')\n",
    "    return(eval_full_batch_reg)\n",
    "\n",
    "def wrapper_combat(adata_full, samples_selected, save_path, suffix='full'):\n",
    "    # combat\n",
    "    adata_full_batch_combat = batch_correct(adata_full, method='combat')\n",
    "    eval_full_batch_combat = eval_batch_sample(adata_full_batch_combat)\n",
    "    eval_full_batch_combat['method'] = 'combat'\n",
    "    eval_full_batch_combat.to_csv(save_path+'scores_combat_'+suffix+'.csv')\n",
    "    return(eval_full_batch_combat)\n",
    "\n",
    "def wrapper_mnn(adata_full, samples_selected, save_path, suffix='full'):\n",
    "    # mnnCorrect\n",
    "    adata_batch_mnn = dict()\n",
    "    max_cells = 1000\n",
    "    #random_state_list = [123465, 87654, 289, 243, 1234]\n",
    "    random_state_list = [19885, 1998, 8768, 26998, 243]\n",
    "    eval_random_state = dict()\n",
    "    for random_state in random_state_list:\n",
    "        for sample in samples_selected:\n",
    "            adata = adata_full[adata_full.obs['sample']==sample,:].copy()\n",
    "            adata_sampled = sample_cells(adata, random_state=random_state, max_cells=max_cells)\n",
    "            adata_sampled_batch_ann = batch_correct(adata_sampled, method='mnn')\n",
    "            adata_batch_mnn[sample] = adata_sampled_batch_ann[sample]\n",
    "        eval_full_mnn = eval_batch_sample(adata_batch_mnn)\n",
    "        eval_random_state[random_state] = eval_full_mnn\n",
    "    eval_full_batch_mnn = pd.concat(eval_random_state)\n",
    "    eval_full_batch_mnn['random_state'] = [x for x in eval_full_batch_mnn.index.get_level_values(0)]\n",
    "    eval_full_batch_mnn.index = range(eval_full_batch_mnn.shape[0])\n",
    "    eval_full_batch_mnn.to_csv(save_path+'scores_mnn_'+suffix+'.csv')\n",
    "    # average score scross random_states\n",
    "    eval_full_batch_mnn['divergence_score'] = pd.to_numeric(eval_full_batch_mnn['divergence_score'])\n",
    "    eval_full_batch_mnn['entropy_score'] = pd.to_numeric(eval_full_batch_mnn['entropy_score'])\n",
    "    eval_full_batch_mnn['silhouette_score'] = pd.to_numeric(eval_full_batch_mnn['silhouette_score'])\n",
    "    eval_full_batch_mnn = eval_full_batch_mnn.drop(columns='random_state')\n",
    "    eval_full_batch_mnn.groupby(['sample']).apply(np.mean)\n",
    "    eval_full_batch_mnn_mean = pd.DataFrame(eval_full_batch_mnn.groupby(['sample']).apply(np.mean))\n",
    "    eval_full_batch_mnn_mean['method'] = 'mnn'\n",
    "    eval_full_batch_mnn_mean['sample'] = eval_full_batch_mnn_mean.index\n",
    "    eval_full_batch_mnn_mean.to_csv(save_path+'scores_mnn_'+suffix+'_mean.csv')\n",
    "    return(eval_full_batch_mnn_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "wd = os.path.abspath(os.path.join(wd,\"..\",\"..\",\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################  simulated data  ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  all cell populations shared  ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming to str index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape (12084, 20)\n",
      "x2 shape (12084, 20)\n"
     ]
    }
   ],
   "source": [
    "data_path = wd+'/simulated/'\n",
    "save_path = wd+'/simulated/eval_scores_upsample/'\n",
    "path = os.path.join(data_path, 'toy_data_gamma_w_index.parquet')\n",
    "df_full = None\n",
    "for sample in ['sample1']:\n",
    "    x1_train, x1_test, x2_train, x2_test = load_data_basic(path,\n",
    "                                 sample=sample, batch_names=['batch1', 'batch2'], panel=None)\n",
    "\n",
    "    tmp_  = pd.concat([x1_train, x2_train])\n",
    "    if df_full is None:\n",
    "        df_full = tmp_\n",
    "    else:\n",
    "        df_full = pd.concat([df_full, tmp_], axis = 0 )\n",
    "\n",
    "metadata_batch = [ i.split('_')[0] for i in df_full.index]\n",
    "metadata_cell = [ i.split('_')[-1] for i in df_full.index]\n",
    "metadata_sample = [ i.split('_')[1] for i in df_full.index]\n",
    "df_full['metadata_batch'] = metadata_batch\n",
    "df_full['metadata_celltype'] = metadata_cell\n",
    "df_full['metadata_sample'] = metadata_sample\n",
    "df_full = df_full.dropna(axis=1)\n",
    "df_full = df_full.reset_index(drop = True)\n",
    "# # global settings\n",
    "# data_path = wd+'/simulated/'\n",
    "# save_path = wd+'/simulated/eval_scores_upsample/'\n",
    "\n",
    "# df_full = pd.read_parquet(data_path+'toy_data_gamma_w_index.parquet')\n",
    "# df_full = df_full.dropna(axis=1)\n",
    "samples_selected = sp.unique(df_full['metadata_sample'])\n",
    "adata_full = convert_to_ann(df_full, sample_col_name = \"metadata_sample\", batch_col_name=\"metadata_batch\",\n",
    "                  celltype_col_name = 'metadata_celltype')\n",
    "adata_full.obs_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "... storing 'sample' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'cell_type' as categorical\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "... storing 'sample' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'cell_type' as categorical\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing cosine normalization...\n",
      "Starting MNN correct iteration. Reference batch: 0\n",
      "Step 1 of 1: processing batch 1\n",
      "  Looking for MNNs...\n",
      "  Computing correction vectors...\n",
      "  Adjusting variance...\n",
      "  Applying correction...\n",
      "MNN correction complete. Gathering output...\n",
      "Packing AnnData object...\n",
      "Done.\n",
      "Performing cosine normalization...\n",
      "Starting MNN correct iteration. Reference batch: 0\n",
      "Step 1 of 1: processing batch 1\n",
      "  Looking for MNNs...\n",
      "  Computing correction vectors...\n",
      "  Adjusting variance...\n",
      "  Applying correction...\n",
      "MNN correction complete. Gathering output...\n",
      "Packing AnnData object...\n",
      "Done.\n",
      "Performing cosine normalization...\n",
      "Starting MNN correct iteration. Reference batch: 0\n",
      "Step 1 of 1: processing batch 1\n",
      "  Looking for MNNs...\n",
      "  Computing correction vectors...\n",
      "  Adjusting variance...\n",
      "  Applying correction...\n",
      "MNN correction complete. Gathering output...\n",
      "Packing AnnData object...\n",
      "Done.\n",
      "Performing cosine normalization...\n",
      "Starting MNN correct iteration. Reference batch: 0\n",
      "Step 1 of 1: processing batch 1\n",
      "  Looking for MNNs...\n",
      "  Computing correction vectors...\n",
      "  Adjusting variance...\n",
      "  Applying correction...\n",
      "MNN correction complete. Gathering output...\n",
      "Packing AnnData object...\n",
      "Done.\n",
      "Performing cosine normalization...\n",
      "Starting MNN correct iteration. Reference batch: 0\n",
      "Step 1 of 1: processing batch 1\n",
      "  Looking for MNNs...\n",
      "  Computing correction vectors...\n",
      "  Adjusting variance...\n",
      "  Applying correction...\n",
      "MNN correction complete. Gathering output...\n",
      "Packing AnnData object...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>divergence_score</th>\n",
       "      <th>entropy_score</th>\n",
       "      <th>method</th>\n",
       "      <th>sample</th>\n",
       "      <th>silhouette_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sample1</td>\n",
       "      <td>0.363898</td>\n",
       "      <td>-1</td>\n",
       "      <td>raw</td>\n",
       "      <td>sample1</td>\n",
       "      <td>-0.0945268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample1</td>\n",
       "      <td>0.0831923</td>\n",
       "      <td>-1</td>\n",
       "      <td>reg</td>\n",
       "      <td>sample1</td>\n",
       "      <td>-0.0361925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample1</td>\n",
       "      <td>0.0365784</td>\n",
       "      <td>-1</td>\n",
       "      <td>combat</td>\n",
       "      <td>sample1</td>\n",
       "      <td>-0.0710457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample1</td>\n",
       "      <td>0.0218221</td>\n",
       "      <td>-1</td>\n",
       "      <td>mnn</td>\n",
       "      <td>sample1</td>\n",
       "      <td>-0.0769231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        divergence_score entropy_score  method   sample silhouette_score\n",
       "sample1         0.363898            -1     raw  sample1       -0.0945268\n",
       "sample1        0.0831923            -1     reg  sample1       -0.0361925\n",
       "sample1        0.0365784            -1  combat  sample1       -0.0710457\n",
       "sample1        0.0218221            -1     mnn  sample1       -0.0769231"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix = 'toy'\n",
    "eval_full_raw = wrapper_raw(adata_full, samples_selected, save_path, suffix)\n",
    "eval_full_batch_reg = wrapper_reg(adata_full, samples_selected, save_path, suffix)\n",
    "eval_full_batch_combat = wrapper_combat(adata_full, samples_selected, save_path, suffix)\n",
    "eval_full_batch_mnn_mean = wrapper_mnn(adata_full, samples_selected, save_path, suffix)\n",
    "\n",
    "# merge all baseline scores\n",
    "eval_all = pd.concat([eval_full_raw, eval_full_batch_reg, eval_full_batch_combat, eval_full_batch_mnn_mean])\n",
    "eval_all.to_csv(save_path+'scores_baselines_full.csv')\n",
    "eval_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  some cell populations shared  ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming to str index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape (9588, 20)\n",
      "x2 shape (9588, 20)\n"
     ]
    }
   ],
   "source": [
    "# global settings\n",
    "data_path = wd+'/simulated/'\n",
    "save_path = wd+'/simulated/eval_scores_subset_upsample/'\n",
    "path = os.path.join(data_path, 'toy_data_gamma_w_index_subset.parquet')\n",
    "df_full = None\n",
    "for sample in ['sample1']:\n",
    "    x1_train, x1_test, x2_train, x2_test = load_data_basic(path,\n",
    "                                 sample=sample, batch_names=['batch1', 'batch2'], panel=None)\n",
    "\n",
    "    tmp_  = pd.concat([x1_train, x2_train])\n",
    "    if df_full is None:\n",
    "        df_full = tmp_\n",
    "    else:\n",
    "        df_full = pd.concat([df_full, tmp_], axis = 0 )\n",
    "\n",
    "metadata_batch = [ i.split('_')[0] for i in df_full.index]\n",
    "metadata_cell = [ i.split('_')[-1] for i in df_full.index]\n",
    "metadata_sample = [ i.split('_')[1] for i in df_full.index]\n",
    "df_full['metadata_batch'] = metadata_batch\n",
    "df_full['metadata_celltype'] = metadata_cell\n",
    "df_full['metadata_sample'] = metadata_sample\n",
    "df_full = df_full.dropna(axis=1)\n",
    "df_full = df_full.reset_index(drop = True)\n",
    "\n",
    "# data_path = wd+'/simulated/'\n",
    "# save_path = wd+'/simulated/eval_scores_subset/'\n",
    "\n",
    "# df_full = pd.read_parquet(data_path+'toy_data_gamma_w_index_subset.parquet')\n",
    "# df_full = df_full.dropna(axis=1)\n",
    "samples_selected = sp.unique(df_full['metadata_sample'])\n",
    "adata_full = convert_to_ann(df_full, sample_col_name = \"metadata_sample\", batch_col_name=\"metadata_batch\",\n",
    "                  celltype_col_name = 'metadata_celltype')\n",
    "adata_full.obs_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "... storing 'sample' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'cell_type' as categorical\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "... storing 'sample' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'cell_type' as categorical\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing cosine normalization...\n",
      "Starting MNN correct iteration. Reference batch: 0\n",
      "Step 1 of 1: processing batch 1\n",
      "  Looking for MNNs...\n",
      "  Computing correction vectors...\n",
      "  Adjusting variance...\n",
      "  Applying correction...\n",
      "MNN correction complete. Gathering output...\n",
      "Packing AnnData object...\n",
      "Done.\n",
      "Performing cosine normalization...\n",
      "Starting MNN correct iteration. Reference batch: 0\n",
      "Step 1 of 1: processing batch 1\n",
      "  Looking for MNNs...\n",
      "  Computing correction vectors...\n",
      "  Adjusting variance...\n",
      "  Applying correction...\n",
      "MNN correction complete. Gathering output...\n",
      "Packing AnnData object...\n",
      "Done.\n",
      "Performing cosine normalization...\n",
      "Starting MNN correct iteration. Reference batch: 0\n",
      "Step 1 of 1: processing batch 1\n",
      "  Looking for MNNs...\n",
      "  Computing correction vectors...\n",
      "  Adjusting variance...\n",
      "  Applying correction...\n",
      "MNN correction complete. Gathering output...\n",
      "Packing AnnData object...\n",
      "Done.\n",
      "Performing cosine normalization...\n",
      "Starting MNN correct iteration. Reference batch: 0\n",
      "Step 1 of 1: processing batch 1\n",
      "  Looking for MNNs...\n",
      "  Computing correction vectors...\n",
      "  Adjusting variance...\n",
      "  Applying correction...\n",
      "MNN correction complete. Gathering output...\n",
      "Packing AnnData object...\n",
      "Done.\n",
      "Performing cosine normalization...\n",
      "Starting MNN correct iteration. Reference batch: 0\n",
      "Step 1 of 1: processing batch 1\n",
      "  Looking for MNNs...\n",
      "  Computing correction vectors...\n",
      "  Adjusting variance...\n",
      "  Applying correction...\n",
      "MNN correction complete. Gathering output...\n",
      "Packing AnnData object...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>divergence_score</th>\n",
       "      <th>entropy_score</th>\n",
       "      <th>method</th>\n",
       "      <th>sample</th>\n",
       "      <th>silhouette_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sample1</td>\n",
       "      <td>0.529782</td>\n",
       "      <td>0.563564</td>\n",
       "      <td>raw</td>\n",
       "      <td>sample1</td>\n",
       "      <td>-0.0993585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample1</td>\n",
       "      <td>0.138001</td>\n",
       "      <td>0.670678</td>\n",
       "      <td>reg</td>\n",
       "      <td>sample1</td>\n",
       "      <td>-0.0391927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample1</td>\n",
       "      <td>0.0498539</td>\n",
       "      <td>0.68209</td>\n",
       "      <td>combat</td>\n",
       "      <td>sample1</td>\n",
       "      <td>-0.101426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample1</td>\n",
       "      <td>0.0391844</td>\n",
       "      <td>0.683331</td>\n",
       "      <td>mnn</td>\n",
       "      <td>sample1</td>\n",
       "      <td>-0.114747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        divergence_score entropy_score  method   sample silhouette_score\n",
       "sample1         0.529782      0.563564     raw  sample1       -0.0993585\n",
       "sample1         0.138001      0.670678     reg  sample1       -0.0391927\n",
       "sample1        0.0498539       0.68209  combat  sample1        -0.101426\n",
       "sample1        0.0391844      0.683331     mnn  sample1        -0.114747"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix = 'toysubset'\n",
    "eval_full_raw = wrapper_raw(adata_full, samples_selected, save_path, suffix)\n",
    "eval_full_batch_reg = wrapper_reg(adata_full, samples_selected, save_path, suffix)\n",
    "eval_full_batch_combat = wrapper_combat(adata_full, samples_selected, save_path, suffix)\n",
    "eval_full_batch_mnn_mean = wrapper_mnn(adata_full, samples_selected, save_path, suffix)\n",
    "\n",
    "# merge all baseline scores\n",
    "eval_all = pd.concat([eval_full_raw, eval_full_batch_reg, eval_full_batch_combat, eval_full_batch_mnn_mean])\n",
    "eval_all.to_csv(save_path+'scores_baselines_full.csv')\n",
    "eval_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################  Chevrier data  ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape (26541, 11)\n",
      "x2 shape (26541, 11)\n",
      "x1 shape (6064, 11)\n",
      "x2 shape (6064, 11)\n",
      "x1 shape (15877, 11)\n",
      "x2 shape (15877, 11)\n"
     ]
    }
   ],
   "source": [
    "from loading_and_preprocessing.data_loader import load_data_basic\n",
    "# global settings\n",
    "data_path = wd+'/Dataset5/'\n",
    "save_path = wd+'/Dataset5/eval_scores_upsample/'\n",
    "\n",
    "path = os.path.join(data_path, 'chevrier_data_pooled_full_panels.parquet')\n",
    "df_full = None\n",
    "for sample in ['sample5','sample75','sample65']:\n",
    "    x1_train, x1_test, x2_train, x2_test = load_data_basic(path,\n",
    "                                 sample=sample, batch_names=['batch1', 'batch3'], panel=None)\n",
    "\n",
    "    tmp_  = pd.concat([x1_train, x2_train])\n",
    "    if df_full is None:\n",
    "        df_full = tmp_\n",
    "    else:\n",
    "        df_full = pd.concat([df_full, tmp_], axis = 0 )\n",
    "\n",
    "metadata_batch = [ i.split('_')[0] for i in df_full.index]\n",
    "metadata_cell = [ i.split('_')[-1] for i in df_full.index]\n",
    "metadata_sample = [ i.split('_')[1] for i in df_full.index]\n",
    "df_full['metadata_batch'] = metadata_batch\n",
    "df_full['metadata_celltype'] = metadata_cell\n",
    "df_full['metadata_sample'] = metadata_sample\n",
    "df_full = df_full.dropna(axis=1)\n",
    "df_full = df_full.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming to str index.\n"
     ]
    }
   ],
   "source": [
    "# # global settings\n",
    "# data_path = wd+'/Dataset5/'\n",
    "# save_path = wd+'/Dataset5/eval_scores_upsample/'\n",
    "\n",
    "# # load data\n",
    "# df_full = pd.read_parquet(data_path+'chevrier_data_pooled_full_panels.parquet')\n",
    "# df_full = df_full.dropna(axis=1)\n",
    "adata_full = convert_to_ann(df_full, sample_col_name = \"metadata_sample\", batch_col_name=\"metadata_batch\",\n",
    "                  celltype_col_name = 'metadata_celltype')\n",
    "adata_full.obs_names_make_unique()\n",
    "# for a quick run subset the data to 3 selected samples\n",
    "samples_selected = ['sample5','sample75','sample65']\n",
    "adata_full = adata_full[adata_full.obs['sample'].isin(samples_selected),:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/utils.py\", line 409:\n",
      "@numba.njit(parallel=True)\n",
      "def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):\n",
      "^\n",
      "\n",
      "  current_graph, n_vertices, n_neighbors, max_candidates, rng_state\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "... storing 'sample' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'cell_type' as categorical\n",
      "... storing 'sample' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'cell_type' as categorical\n",
      "... storing 'sample' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'cell_type' as categorical\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "... storing 'sample' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'cell_type' as categorical\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"_it_sol\" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311)\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py\", line 311:\n",
      "def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:\n",
      "    <source elided>\n",
      "        g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old)\n",
      "        sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1]))\n",
      "        ^\n",
      "\n",
      "[1] During: typing of assignment at /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313)\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py\", line 313:\n",
      "def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:\n",
      "    <source elided>\n",
      "        sum2 = sum2 ** 2\n",
      "        sum2 = sum2.sum(axis=1)\n",
      "        ^\n",
      "\n",
      "  @numba.jit\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"_it_sol\" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py\", line 305:\n",
      "def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:\n",
      "    <source elided>\n",
      "    change = 1\n",
      "    count = 0\n",
      "    ^\n",
      "\n",
      "  @numba.jit\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"_it_sol\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py\", line 270:\n",
      "@numba.jit\n",
      "def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py\", line 270:\n",
      "@numba.jit\n",
      "def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"_it_sol\" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311)\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py\", line 311:\n",
      "def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:\n",
      "    <source elided>\n",
      "        g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old)\n",
      "        sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1]))\n",
      "        ^\n",
      "\n",
      "[1] During: typing of assignment at /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313)\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py\", line 313:\n",
      "def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:\n",
      "    <source elided>\n",
      "        sum2 = sum2 ** 2\n",
      "        sum2 = sum2.sum(axis=1)\n",
      "        ^\n",
      "\n",
      "  @numba.jit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"_it_sol\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py\", line 305:\n",
      "def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:\n",
      "    <source elided>\n",
      "    change = 1\n",
      "    count = 0\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py\", line 305:\n",
      "def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:\n",
      "    <source elided>\n",
      "    change = 1\n",
      "    count = 0\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "... storing 'sample' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'cell_type' as categorical\n",
      "... storing 'sample' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'cell_type' as categorical\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"l2_norm\" failed type inference due to: Invalid use of Function(<function norm at 0x1062afb00>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A))\n",
      " * parameterized\n",
      "In definition 0:\n",
      "    TypeError: norm_impl() got an unexpected keyword argument 'x'\n",
      "    raised from /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typing/templates.py:517\n",
      "In definition 1:\n",
      "    TypeError: norm_impl() got an unexpected keyword argument 'x'\n",
      "    raised from /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typing/templates.py:517\n",
      "This error is usually caused by passing an argument of a type that is unsupported by the named function.\n",
      "[1] During: resolving callee type: Function(<function norm at 0x1062afb00>)\n",
      "[2] During: typing of call at /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py (16)\n",
      "\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 16:\n",
      "def l2_norm(in_matrix):\n",
      "    return np.linalg.norm(x=in_matrix, axis=1)\n",
      "    ^\n",
      "\n",
      "  @jit(float32[:](float32[:, :]), nogil=True)\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"l2_norm\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 15:\n",
      "@jit(float32[:](float32[:, :]), nogil=True)\n",
      "def l2_norm(in_matrix):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 15:\n",
      "@jit(float32[:](float32[:, :]), nogil=True)\n",
      "def l2_norm(in_matrix):\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.\n",
      "  @jit(float32[:](float32[:, :]), nogil=True)\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:29: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 1d, A), array(float32, 1d, A))\n",
      "  dist[i, j] = np.dot(m[i], n[j])\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"find_mutual_nn\" failed type inference due to: Untyped global name 'cKDTree': cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 90:\n",
      "def find_mutual_nn(data1, data2, k1, k2, n_jobs):\n",
      "    k_index_1 = cKDTree(data1).query(x=data2, k=k1, n_jobs=n_jobs)[1]\n",
      "    ^\n",
      "\n",
      "  @jit((float32[:, :], float32[:, :], int8, int8, int8))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"find_mutual_nn\" failed type inference due to: Untyped global name 'cKDTree': cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 90:\n",
      "def find_mutual_nn(data1, data2, k1, k2, n_jobs):\n",
      "    k_index_1 = cKDTree(data1).query(x=data2, k=k1, n_jobs=n_jobs)[1]\n",
      "    ^\n",
      "\n",
      "  @jit((float32[:, :], float32[:, :], int8, int8, int8))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"find_mutual_nn\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 89:\n",
      "@jit((float32[:, :], float32[:, :], int8, int8, int8))\n",
      "def find_mutual_nn(data1, data2, k1, k2, n_jobs):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 89:\n",
      "@jit((float32[:, :], float32[:, :], int8, int8, int8))\n",
      "def find_mutual_nn(data1, data2, k1, k2, n_jobs):\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"compute_correction\" failed type inference due to: Invalid use of Function(<function unique at 0x1063618c0>) with argument(s) of type(s): (array(int32, 1d, A), return_counts=bool)\n",
      " * parameterized\n",
      "In definition 0:\n",
      "    TypeError: np_unique() got an unexpected keyword argument 'return_counts'\n",
      "    raised from /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typing/templates.py:517\n",
      "In definition 1:\n",
      "    TypeError: np_unique() got an unexpected keyword argument 'return_counts'\n",
      "    raised from /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typing/templates.py:517\n",
      "This error is usually caused by passing an argument of a type that is unsupported by the named function.\n",
      "[1] During: resolving callee type: Function(<function unique at 0x1063618c0>)\n",
      "[2] During: typing of call at /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py (105)\n",
      "\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 105:\n",
      "def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):\n",
      "    <source elided>\n",
      "    vect = data1[mnn1] - data2[mnn2]\n",
      "    mnn_index, mnn_count = np.unique(mnn2, return_counts=True)\n",
      "    ^\n",
      "\n",
      "  @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"compute_correction\" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 107:\n",
      "def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):\n",
      "    <source elided>\n",
      "    vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32)\n",
      "    for index, ve in zip(mnn2, vect):\n",
      "    ^\n",
      "\n",
      "  @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"compute_correction\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 103:\n",
      "@jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32))\n",
      "def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 103:\n",
      "@jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32))\n",
      "def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:199: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"adjust_s_variance\" failed type inference due to: Untyped global name 'sq_dist_to_line': cannot determine Numba type of <class 'numba.ir.UndefinedType'>\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 209:\n",
      "def adjust_s_variance(data1, data2, curcell, curvect, sigma):\n",
      "    <source elided>\n",
      "        sameproj = np.dot(grad, samecell)\n",
      "        samedist = sq_dist_to_line(curcell, grad, samecell)\n",
      "        ^\n",
      "\n",
      "  @jit(float32(float32[:, :], float32[:, :], float32[:], float32[:], float32), nogil=True)\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:199: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"adjust_s_variance\" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 207:\n",
      "def adjust_s_variance(data1, data2, curcell, curvect, sigma):\n",
      "    <source elided>\n",
      "    totalprob2 = 0.\n",
      "    for samecell in data2:\n",
      "    ^\n",
      "\n",
      "  @jit(float32(float32[:, :], float32[:, :], float32[:], float32[:], float32), nogil=True)\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"adjust_s_variance\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 200:\n",
      "@jit(float32(float32[:, :], float32[:, :], float32[:], float32[:], float32), nogil=True)\n",
      "def adjust_s_variance(data1, data2, curcell, curvect, sigma):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 200:\n",
      "@jit(float32(float32[:, :], float32[:, :], float32[:], float32[:], float32), nogil=True)\n",
      "def adjust_s_variance(data1, data2, curcell, curvect, sigma):\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:199: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.\n",
      "  @jit(float32(float32[:, :], float32[:, :], float32[:], float32[:], float32), nogil=True)\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:238: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 1d, C), array(float32, 1d, A))\n",
      "  scale = np.dot(working, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing cosine normalization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"l2_norm\" failed type inference due to: Invalid use of Function(<function norm at 0x1062afb00>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A))\n",
      " * parameterized\n",
      "In definition 0:\n",
      "    TypeError: norm_impl() got an unexpected keyword argument 'x'\n",
      "    raised from /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typing/templates.py:517\n",
      "In definition 1:\n",
      "    TypeError: norm_impl() got an unexpected keyword argument 'x'\n",
      "    raised from /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typing/templates.py:517\n",
      "This error is usually caused by passing an argument of a type that is unsupported by the named function.\n",
      "[1] During: resolving callee type: Function(<function norm at 0x1062afb00>)\n",
      "[2] During: typing of call at /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py (16)\n",
      "\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 16:\n",
      "def l2_norm(in_matrix):\n",
      "    return np.linalg.norm(x=in_matrix, axis=1)\n",
      "    ^\n",
      "\n",
      "  @jit(float32[:](float32[:, :]), nogil=True)\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"l2_norm\" failed type inference due to: Invalid use of Function(<function norm at 0x1062afb00>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A))\n",
      " * parameterized\n",
      "In definition 0:\n",
      "    TypeError: norm_impl() got an unexpected keyword argument 'x'\n",
      "    raised from /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typing/templates.py:517\n",
      "In definition 1:\n",
      "    TypeError: norm_impl() got an unexpected keyword argument 'x'\n",
      "    raised from /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/typing/templates.py:517\n",
      "This error is usually caused by passing an argument of a type that is unsupported by the named function.\n",
      "[1] During: resolving callee type: Function(<function norm at 0x1062afb00>)\n",
      "[2] During: typing of call at /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py (16)\n",
      "\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 16:\n",
      "def l2_norm(in_matrix):\n",
      "    return np.linalg.norm(x=in_matrix, axis=1)\n",
      "    ^\n",
      "\n",
      "  @jit(float32[:](float32[:, :]), nogil=True)\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"l2_norm\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 15:\n",
      "@jit(float32[:](float32[:, :]), nogil=True)\n",
      "def l2_norm(in_matrix):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"l2_norm\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 15:\n",
      "@jit(float32[:](float32[:, :]), nogil=True)\n",
      "def l2_norm(in_matrix):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 15:\n",
      "@jit(float32[:](float32[:, :]), nogil=True)\n",
      "def l2_norm(in_matrix):\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 15:\n",
      "@jit(float32[:](float32[:, :]), nogil=True)\n",
      "def l2_norm(in_matrix):\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.\n",
      "  @jit(float32[:](float32[:, :]), nogil=True)\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.\n",
      "  @jit(float32[:](float32[:, :]), nogil=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MNN correct iteration. Reference batch: 0\n",
      "Step 1 of 1: processing batch 1\n",
      "  Looking for MNNs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"find_mutual_nn\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py (94)\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 94:\n",
      "def find_mutual_nn(data1, data2, k1, k2, n_jobs):\n",
      "    <source elided>\n",
      "    mutual_2 = []\n",
      "    for index_2 in range(data2.shape[0]):\n",
      "    ^\n",
      "\n",
      "  @jit((float32[:, :], float32[:, :], int8, int8, int8))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"find_mutual_nn\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 94:\n",
      "def find_mutual_nn(data1, data2, k1, k2, n_jobs):\n",
      "    <source elided>\n",
      "    mutual_2 = []\n",
      "    for index_2 in range(data2.shape[0]):\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 94:\n",
      "def find_mutual_nn(data1, data2, k1, k2, n_jobs):\n",
      "    <source elided>\n",
      "    mutual_2 = []\n",
      "    for index_2 in range(data2.shape[0]):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Computing correction vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/ir_utils.py:1969: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 107:\n",
      "def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):\n",
      "    <source elided>\n",
      "    vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32)\n",
      "    for index, ve in zip(mnn2, vect):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function compute_correction failed at nopython mode lowering due to: iterating over 2D array\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 107:\n",
      "def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):\n",
      "    <source elided>\n",
      "    vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32)\n",
      "    for index, ve in zip(mnn2, vect):\n",
      "    ^\n",
      "\n",
      "[1] During: lowering \"$78.2 = iternext(value=$phi78.1)\" at /Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py (107)\n",
      "  @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"compute_correction\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 107:\n",
      "def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):\n",
      "    <source elided>\n",
      "    vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32)\n",
      "    for index, ve in zip(mnn2, vect):\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../../anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/utils.py\", line 107:\n",
      "def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):\n",
      "    <source elided>\n",
      "    vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32)\n",
      "    for index, ve in zip(mnn2, vect):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Adjusting variance...\n",
      "  Applying correction...\n",
      "MNN correction complete. Gathering output...\n",
      "Packing AnnData object...\n",
      "Done.\n",
      "Performing cosine normalization...\n",
      "Starting MNN correct iteration. Reference batch: 0\n",
      "Step 1 of 1: processing batch 1\n",
      "  Looking for MNNs...\n",
      "  Computing correction vectors...\n",
      "  Adjusting variance...\n",
      "  Applying correction...\n",
      "MNN correction complete. Gathering output...\n",
      "Packing AnnData object...\n",
      "Done.\n",
      "Performing cosine normalization...\n",
      "Starting MNN correct iteration. Reference batch: 0\n",
      "Step 1 of 1: processing batch 1\n",
      "  Looking for MNNs...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1000 is out of bounds for axis 0 with size 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-77d7cd22d1c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meval_full_batch_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0meval_full_batch_combat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_combat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0meval_full_batch_mnn_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_mnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# merge all baseline scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-088990c65008>\u001b[0m in \u001b[0;36mwrapper_mnn\u001b[0;34m(adata_full, samples_selected, save_path, suffix)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0madata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madata_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madata_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0madata_sampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_cells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cells\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_cells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0madata_sampled_batch_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_correct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata_sampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mnn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0madata_batch_mnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madata_sampled_batch_ann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0meval_full_mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_batch_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata_batch_mnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/courses/DeepLearning/DL2019/project/2019_DL_Class/baselines/baselines_helpers.py\u001b[0m in \u001b[0;36mbatch_correct\u001b[0;34m(adata, method)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mdf_batch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             df_batch = sc.external.pp.mnn_correct(df_batch1, df_batch2, key='batch',\n\u001b[0;32m--> 115\u001b[0;31m                                                        do_concatenate=True, n_jobs=1)[0]\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0madata_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/scanpy/preprocessing/_mnn_correct.py\u001b[0m in \u001b[0;36mmnn_correct\u001b[0;34m(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mbatch_categories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_norm_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcos_norm_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_norm_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcos_norm_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0msvd_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvd_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_adj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar_adj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_angle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_angle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnn_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnn_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvd_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs)\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnn_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/mnn.py\u001b[0m in \u001b[0;36mmnn_correct\u001b[0;34m(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m                                 \u001b[0mcos_norm_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcos_norm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvd_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_adj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar_adj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                                 \u001b[0mcompute_angle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_angle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnn_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnn_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                                 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs)\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Packing AnnData object...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_concatenate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/mnnpy/mnn.py\u001b[0m in \u001b[0;36mmnn_correct\u001b[0;34m(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Looking for MNNs...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,\n\u001b[0;32m--> 179\u001b[0;31m                                           n_jobs=n_jobs)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Computing correction vectors...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1000 is out of bounds for axis 0 with size 1000"
     ]
    }
   ],
   "source": [
    "suffix='full'\n",
    "eval_full_raw = wrapper_raw(adata_full, samples_selected, save_path, suffix)\n",
    "eval_full_batch_reg = wrapper_reg(adata_full, samples_selected, save_path, suffix)\n",
    "eval_full_batch_combat = wrapper_combat(adata_full, samples_selected, save_path, suffix)\n",
    "eval_full_batch_mnn_mean = wrapper_mnn(adata_full, samples_selected, save_path, suffix)\n",
    "\n",
    "# merge all baseline scores\n",
    "eval_all = pd.concat([eval_full_raw, eval_full_batch_reg, eval_full_batch_combat, eval_full_batch_mnn_mean])\n",
    "eval_all = eval_all.sort_values(by=['sample', 'method'])\n",
    "eval_all.to_csv(save_path+'scores_baselines_full.csv')\n",
    "eval_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannaf/anaconda3/envs/dl/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>divergence_score</th>\n",
       "      <th>entropy_score</th>\n",
       "      <th>method</th>\n",
       "      <th>sample</th>\n",
       "      <th>silhouette_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sample5</td>\n",
       "      <td>0.462772</td>\n",
       "      <td>0.536786</td>\n",
       "      <td>combat</td>\n",
       "      <td>sample5</td>\n",
       "      <td>0.212167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample5</td>\n",
       "      <td>0.771196</td>\n",
       "      <td>0.616088</td>\n",
       "      <td>mnn</td>\n",
       "      <td>sample5</td>\n",
       "      <td>0.183975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample5</td>\n",
       "      <td>1.16913</td>\n",
       "      <td>0.514197</td>\n",
       "      <td>raw</td>\n",
       "      <td>sample5</td>\n",
       "      <td>0.045573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample5</td>\n",
       "      <td>1.1116</td>\n",
       "      <td>0.288478</td>\n",
       "      <td>reg</td>\n",
       "      <td>sample5</td>\n",
       "      <td>0.21912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample65</td>\n",
       "      <td>0.414426</td>\n",
       "      <td>0.554443</td>\n",
       "      <td>combat</td>\n",
       "      <td>sample65</td>\n",
       "      <td>0.235609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample65</td>\n",
       "      <td>0.508363</td>\n",
       "      <td>0.647851</td>\n",
       "      <td>mnn</td>\n",
       "      <td>sample65</td>\n",
       "      <td>0.11293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample65</td>\n",
       "      <td>1.00274</td>\n",
       "      <td>0.543765</td>\n",
       "      <td>raw</td>\n",
       "      <td>sample65</td>\n",
       "      <td>0.0782595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample65</td>\n",
       "      <td>0.794367</td>\n",
       "      <td>0.272582</td>\n",
       "      <td>reg</td>\n",
       "      <td>sample65</td>\n",
       "      <td>0.168349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample75</td>\n",
       "      <td>0.358697</td>\n",
       "      <td>0.556734</td>\n",
       "      <td>combat</td>\n",
       "      <td>sample75</td>\n",
       "      <td>-0.0254128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample75</td>\n",
       "      <td>0.820883</td>\n",
       "      <td>0.609393</td>\n",
       "      <td>mnn</td>\n",
       "      <td>sample75</td>\n",
       "      <td>0.000838843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample75</td>\n",
       "      <td>2.44027</td>\n",
       "      <td>0.559476</td>\n",
       "      <td>raw</td>\n",
       "      <td>sample75</td>\n",
       "      <td>-0.205819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sample75</td>\n",
       "      <td>1.85874</td>\n",
       "      <td>0.0875021</td>\n",
       "      <td>reg</td>\n",
       "      <td>sample75</td>\n",
       "      <td>-0.0424926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         divergence_score entropy_score  method    sample silhouette_score\n",
       "sample5          0.462772      0.536786  combat   sample5         0.212167\n",
       "sample5          0.771196      0.616088     mnn   sample5         0.183975\n",
       "sample5           1.16913      0.514197     raw   sample5         0.045573\n",
       "sample5            1.1116      0.288478     reg   sample5          0.21912\n",
       "sample65         0.414426      0.554443  combat  sample65         0.235609\n",
       "sample65         0.508363      0.647851     mnn  sample65          0.11293\n",
       "sample65          1.00274      0.543765     raw  sample65        0.0782595\n",
       "sample65         0.794367      0.272582     reg  sample65         0.168349\n",
       "sample75         0.358697      0.556734  combat  sample75       -0.0254128\n",
       "sample75         0.820883      0.609393     mnn  sample75      0.000838843\n",
       "sample75          2.44027      0.559476     raw  sample75        -0.205819\n",
       "sample75          1.85874     0.0875021     reg  sample75       -0.0424926"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_all = pd.concat([eval_full_raw, eval_full_batch_reg, eval_full_batch_combat, eval_full_batch_mnn_mean])\n",
    "eval_all = eval_all.sort_values(by=['sample', 'method'])\n",
    "eval_all.to_csv(save_path+'scores_baselines_full_upsample.csv')\n",
    "eval_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
