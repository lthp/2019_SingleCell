{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README\n",
    "A notebook to compute evaluation scores for raw data as well as bacth corrected using besline methods: regressing batch effect out, ComBat and mnnCorrect. The workflow is run for both, the simulated and real-world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os \n",
    "import glob\n",
    "import sys\n",
    "from FlowCytometryTools import FCMeasurement\n",
    "from collections import Counter\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import xlrd\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "import scipy as sp\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from visualisation_and_evaluation.helpers_eval import cal_UMAP, entropy, cal_entropy, evaluate_scores, separate_metadata\n",
    "from baselines.baselines_helpers import scale, convert_to_ann, sample_cells, batch_correct, prep_anndata_for_eval, eval_batch_sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_raw(adata_full, samples_selected, save_path):\n",
    "    # raw scores\n",
    "    adata_full_dict = dict()\n",
    "    for sample in samples_selected:\n",
    "        adata_full_dict[sample] = adata_full[adata_full.obs['sample']==sample].copy()\n",
    "    eval_full_raw = eval_batch_sample(adata_full_dict)\n",
    "    eval_full_raw['method'] = 'raw'\n",
    "    eval_full_raw.to_csv(save_path+'scores_raw_full.csv')\n",
    "    return(eval_full_raw)\n",
    "\n",
    "def wrapper_reg(adata_full, samples_selected, save_path):\n",
    "    # regress out batch effect\n",
    "    adata_full_batch_reg = batch_correct(adata_full, method='reg')\n",
    "    eval_full_batch_reg = eval_batch_sample(adata_full_batch_reg)\n",
    "    eval_full_batch_reg['method'] = 'reg'\n",
    "    eval_full_batch_reg.to_csv(save_path+'scores_reg_full.csv')\n",
    "    return(eval_full_batch_reg)\n",
    "\n",
    "def wrapper_combat(adata_full, samples_selected, save_path):\n",
    "    # combat\n",
    "    adata_full_batch_combat = batch_correct(adata_full, method='combat')\n",
    "    eval_full_batch_combat = eval_batch_sample(adata_full_batch_combat)\n",
    "    eval_full_batch_combat['method'] = 'combat'\n",
    "    eval_full_batch_combat.to_csv(save_path+'scores_combat_full.csv')\n",
    "    return(eval_full_batch_combat)\n",
    "\n",
    "def wrapper_mnn(adata_full, samples_selected, save_path):\n",
    "    # mnnCorrect\n",
    "    adata_batch_mnn = dict()\n",
    "    max_cells = 1000\n",
    "    random_state_list = [123465, 87654, 289, 243, 1234]\n",
    "    eval_random_state = dict()\n",
    "    for random_state in random_state_list:\n",
    "        for sample in samples_selected:\n",
    "            adata = adata_full[adata_full.obs['sample']==sample,:].copy()\n",
    "            adata_sampled = sample_cells(adata, random_state=random_state, max_cells=max_cells)\n",
    "            adata_sampled_batch_ann = batch_correct(adata_sampled, method='mnn')\n",
    "            adata_batch_mnn[sample] = adata_sampled_batch_ann[sample]\n",
    "        eval_full_mnn = eval_batch_sample(adata_batch_mnn)\n",
    "        eval_random_state[random_state] = eval_full_mnn\n",
    "    eval_full_batch_mnn = pd.concat(eval_random_state)\n",
    "    eval_full_batch_mnn['random_state'] = [x for x in eval_full_batch_mnn.index.get_level_values(0)]\n",
    "    eval_full_batch_mnn.index = range(eval_full_batch_mnn.shape[0])\n",
    "    eval_full_batch_mnn.to_csv(save_path+'scores_mnn_full.csv')\n",
    "    # average score scross random_states\n",
    "    eval_full_batch_mnn['divergence_score'] = pd.to_numeric(eval_full_batch_mnn['divergence_score'])\n",
    "    eval_full_batch_mnn['entropy_score'] = pd.to_numeric(eval_full_batch_mnn['entropy_score'])\n",
    "    eval_full_batch_mnn['silhouette_score'] = pd.to_numeric(eval_full_batch_mnn['silhouette_score'])\n",
    "    eval_full_batch_mnn = eval_full_batch_mnn.drop(columns='random_state')\n",
    "    eval_full_batch_mnn.groupby(['sample']).apply(np.mean)\n",
    "    eval_full_batch_mnn_mean = pd.DataFrame(eval_full_batch_mnn.groupby(['sample']).apply(np.mean))\n",
    "    eval_full_batch_mnn_mean['method'] = 'mnn'\n",
    "    eval_full_batch_mnn_mean['sample'] = eval_full_batch_mnn_mean.index\n",
    "    eval_full_batch_mnn_mean.to_csv(save_path+'scores_mnn_full_mean.csv')\n",
    "    return(eval_full_batch_mnn_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################  simulated data  ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  all cell populations shared  ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings\n",
    "data_path = '/Users/joannaf/Desktop/courses/DeepLearning/DL2019/project/data/simulated/'\n",
    "save_path = '/Users/joannaf/Desktop/courses/DeepLearning/DL2019/project/data/simulated/eval_scores/'\n",
    "\n",
    "df_full = pd.read_parquet(data_path+'toy_data_gamma_w_index.parquet')\n",
    "df_full = df_full.dropna(axis=1)\n",
    "samples_selected = sp.unique(df_full['metadata_sample'])\n",
    "adata_full = convert_to_ann(df_full, sample_col_name = \"metadata_sample\", batch_col_name=\"metadata_batch\",\n",
    "                  celltype_col_name = 'metadata_celltype')\n",
    "adata_full.obs_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_full_raw = wrapper_raw(adata_full, samples_selected, save_path)\n",
    "eval_full_batch_reg = wrapper_reg(adata_full, samples_selected, save_path)\n",
    "eval_full_batch_combat = wrapper_combat(adata_full, samples_selected, save_path)\n",
    "eval_full_batch_mnn_mean = wrapper_mnn(adata_full, samples_selected, save_path)\n",
    "\n",
    "# merge all baseline scores\n",
    "eval_all = pd.concat([eval_full_raw, eval_full_batch_reg, eval_full_batch_combat, eval_full_batch_mnn_mean])\n",
    "eval_all.to_csv(save_path+'scores_baselines_full.csv')\n",
    "eval_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  some cell populations shared  ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings\n",
    "data_path = '/Users/joannaf/Desktop/courses/DeepLearning/DL2019/project/data/simulated/'\n",
    "save_path = '/Users/joannaf/Desktop/courses/DeepLearning/DL2019/project/data/simulated/eval_scores_subset/'\n",
    "\n",
    "df_full = pd.read_parquet(data_path+'toy_data_gamma_w_index_subset.parquet')\n",
    "df_full = df_full.dropna(axis=1)\n",
    "samples_selected = sp.unique(df_full['metadata_sample'])\n",
    "adata_full = convert_to_ann(df_full, sample_col_name = \"metadata_sample\", batch_col_name=\"metadata_batch\",\n",
    "                  celltype_col_name = 'metadata_celltype')\n",
    "adata_full.obs_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_full_raw = wrapper_raw(adata_full, samples_selected, save_path)\n",
    "eval_full_batch_reg = wrapper_reg(adata_full, samples_selected, save_path)\n",
    "eval_full_batch_combat = wrapper_combat(adata_full, samples_selected, save_path)\n",
    "eval_full_batch_mnn_mean = wrapper_mnn(adata_full, samples_selected, save_path)\n",
    "\n",
    "# merge all baseline scores\n",
    "eval_all = pd.concat([eval_full_raw, eval_full_batch_reg, eval_full_batch_combat, eval_full_batch_mnn_mean])\n",
    "eval_all.to_csv(save_path+'scores_baselines_full.csv')\n",
    "eval_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################  Chevrier data  ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings\n",
    "data_path = '/Users/joannaf/Desktop/courses/DeepLearning/DL2019/project/data/Dataset5/'\n",
    "save_path = '/Users/joannaf/Desktop/courses/DeepLearning/DL2019/project/data/Dataset5/eval_scores/'\n",
    "\n",
    "# load data\n",
    "df_full = pd.read_parquet(data_path+'chevrier_data_pooled_full_panels.parquet')\n",
    "df_full = df_full.dropna(axis=1)\n",
    "adata_full = convert_to_ann(df_full, sample_col_name = \"metadata_sample\", batch_col_name=\"metadata_batch\",\n",
    "                  celltype_col_name = 'metadata_celltype')\n",
    "adata_full.obs_names_make_unique()\n",
    "# for a quick run subset the data to 3 selected samples\n",
    "samples_selected = ['sample5','sample75','sample65']\n",
    "adata_full = adata_full[adata_full.obs['sample'].isin(samples_selected),:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_full_raw = wrapper_raw(adata_full, samples_selected, save_path)\n",
    "eval_full_batch_reg = wrapper_reg(adata_full, samples_selected, save_path)\n",
    "eval_full_batch_combat = wrapper_combat(adata_full, samples_selected, save_path)\n",
    "eval_full_batch_mnn_mean = wrapper_mnn(adata_full, samples_selected, save_path)\n",
    "\n",
    "# merge all baseline scores\n",
    "eval_all = pd.concat([eval_full_raw, eval_full_batch_reg, eval_full_batch_combat, eval_full_batch_mnn_mean])\n",
    "eval_all.to_csv(save_path+'scores_baselines_full.csv')\n",
    "eval_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
