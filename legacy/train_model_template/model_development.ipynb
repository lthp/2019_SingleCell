{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.python.keras.layers import Input, Dense, Lambda, Flatten, Reshape, Concatenate\n",
    "from tensorflow.python.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, LeakyReLU\n",
    "from tensorflow.python.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.keras import metrics\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.python.keras.datasets import mnist\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "\n",
    "import pdb\n",
    "import os\n",
    "\n",
    "from train_model_template.helpers_vizualisation import eval_knn_proportions\n",
    "from train_model_template.helpers_vizualisation import plot_tsne\n",
    "from train_model_template.helpers_vizualisation import plot_umap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: after discussion last time the data has one concatanated index with all the information\n",
    "def load_data_basic(path, patient='sample1', batch_names = ['batch1', 'batch2'], seed=42,\n",
    "                   n_cells_to_select = 500):\n",
    "    \"\"\"\n",
    "    Function to load data and split into 2 inputs with train and test sets\n",
    "    inputs:\n",
    "        path: path to the data file\n",
    "        patient: name of the patient to consider\n",
    "        batch_names: a list of batch names to split the data\n",
    "        n_cells_to_select: number of cells to select for quicker runs, if 0 then all cells are selected\n",
    "    outputs:\n",
    "        x1_train, x1_test: train and test sets form the first batch\n",
    "        x2_train, x2_test: train and test sets form the second batch    \n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(path, engine='pyarrow')\n",
    "    selected_cols = [col for col in df.columns if not \"metadata\" in col]\n",
    "    df = df.loc[:,selected_cols]\n",
    "    idx = df.index.get_values()\n",
    "    x1_idx = [x for x in idx if patient in x and batch_names[0] in x and patient+'0' not in x][0]\n",
    "    x1 = df.loc[x1_idx,:].copy()\n",
    "    x2_idx = [x for x in idx if patient in x and batch_names[1] in x and patient+'0' not in x][0]\n",
    "    x2 = df.loc[x2_idx,:].copy()\n",
    "    if(n_cells_to_select>0):\n",
    "        cells_to_select = np.random.uniform(0,x1.shape[0], n_cells_to_select)\n",
    "        x1 = x1.iloc[cells_to_select, :]\n",
    "        cells_to_select = np.random.uniform(0,x2.shape[0], n_cells_to_select)\n",
    "        x2 = x2.iloc[cells_to_select, :]\n",
    "    x1_train, x1_test = train_test_split(x1, test_size=0.2, random_state=42)\n",
    "    x2_train, x2_test = train_test_split(x2, test_size=0.2, random_state=42)\n",
    "    return(x1_train, x1_test, x2_train, x2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# DATA LOADING ############# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path = path+'/toy_data_gamma_small.parquet' # '/toy_data_gamma_large.parquet'\n",
    "x1_train, x1_test, x2_train, x2_test = load_data_basic(path, patient='sample1', batch_names = ['batch1', 'batch2'], seed=42,\n",
    "                                                      n_cells_to_select=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############    MODEL     #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# VISUALIZATIONS ############# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: x1_test should be replaced with with model output\n",
    "plot_tsne(x1_test, do_pca = True, n_plots = 2, iter_ = 500, pca_components = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umap(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_knn_proportions(x1_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
